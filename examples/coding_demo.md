# å¯¦æˆ°æ“ä½œï¼šæ’°å¯«ç¨‹å¼ (Writing Code)

## æƒ…å¢ƒ
æˆ‘å€‘éœ€è¦åœ¨ä¸€å€‹ Python å°ˆæ¡ˆä¸­ï¼Œå¯¦ä½œä¸€å€‹ç°¡å–®çš„ç¶²é æ¨™é¡ŒæŠ“å–åŠŸèƒ½ (`scraper.py`)ï¼Œä¸¦ä¸”ç‚ºå…¶åŠ ä¸Šæ¸¬è©¦ã€‚

---

## å‚³çµ±åšæ³• (Traditional Workflow)
1.  **æ€è€ƒ**ï¼šæˆ‘éœ€è¦ `requests` å’Œ `BeautifulSoup`ã€‚
2.  **æœå°‹/è©¢å•**ï¼šåœ¨ ChatGPT è¼¸å…¥ã€Œå¯«ä¸€å€‹ Python å‡½æ•¸ç”¨ requests å’Œ bs4 æŠ“å– titleã€ã€‚
3.  **è¤‡è£½è²¼ä¸Š**ï¼šå°‡ç”Ÿæˆçš„ç¨‹å¼ç¢¼è¤‡è£½ã€‚
4.  **åˆ‡æ›è¦–çª—**ï¼šæ‰“é–‹ VS Codeï¼Œå»ºç«‹ `scraper.py`ï¼Œè²¼ä¸Šç¨‹å¼ç¢¼ã€‚
5.  **åŸ·è¡Œæ¸¬è©¦**ï¼šæ‰‹å‹•åŸ·è¡Œ `python scraper.py`ï¼Œç™¼ç¾æ²’æœ‰å®‰è£å¥—ä»¶ã€‚
6.  **é™¤éŒ¯**ï¼šåŸ·è¡Œ `pip install requests beautifulsoup4`ã€‚
7.  **å†æ¬¡åŸ·è¡Œ**ï¼šç™¼ç¾ç¨‹å¼ç¢¼æœ‰èªæ³•éŒ¯èª¤æˆ–é‚è¼¯æ¼æ´ï¼Œè¤‡è£½éŒ¯èª¤è¨Šæ¯å› ChatGPT...

ğŸ”´ **ç¼ºé»**ï¼šé »ç¹åˆ‡æ›è¦–çª—ã€æ‰‹å·¥æ“ä½œå¤šã€å®¹æ˜“æ‰“æ–·å¿ƒæµã€‚

---

## Antigravity åšæ³• (Agentic Workflow)

### 1. å•Ÿå‹•å°è©± (Chat Interface)
åœ¨ IDE å³å´çš„ **Chat é¢æ¿**ï¼ˆæˆ–ä½¿ç”¨å¿«æ·éµ `Cmd+L` å–šèµ·ï¼‰ï¼Œè¼¸å…¥ä»¥ä¸‹é«˜å±¤æ¬¡æŒ‡ä»¤ï¼š

> "åœ¨ `src/scraper.py` å¯¦ä½œä¸€å€‹æŠ“å–ç¶²é æ¨™é¡Œçš„åŠŸèƒ½ï¼ˆä½¿ç”¨ requests å’Œ bs4ï¼‰ï¼Œä¸¦åœ¨ `tests/test_scraper.py` åŠ ä¸Šç›¸æ‡‰çš„ pytest æ¸¬è©¦æ¡ˆä¾‹ã€‚è«‹ç¢ºä¿è™•ç†é€£ç·šéŒ¯èª¤çš„æƒ…æ³ã€‚"

### 2. å¯©é–±èˆ‡åŸ·è¡Œ (Review & Execute)
Agent æ¥æ”¶æŒ‡ä»¤å¾Œæœƒé¡¯ç¤ºæ“¬å®šçš„è¨ˆç•«ã€‚
1.  **ç¢ºèªè¨ˆç•«**ï¼šæŸ¥çœ‹ Agent æ‰“ç®—å»ºç«‹å“ªäº›æª”æ¡ˆã€‚
2.  **ä¸€éµåŸ·è¡Œ**ï¼šé»æ“Š **ã€ŒRunã€** æˆ– **ã€ŒProceedã€** æŒ‰éˆ•ã€‚

### 3. Agent è‡ªå‹•åŒ–åŸ·è¡Œ (Automation)
Agent æœƒè‡ªå‹•é€²è¡Œä»¥ä¸‹æ­¥é©Ÿï¼Œä½ åªéœ€åœ¨è¢å¹•ä¸Šçœ‹è‘—å®ƒæ“ä½œï¼š

1.  **ç’°å¢ƒæª¢æŸ¥**ï¼šæª¢æŸ¥ `requirements.txt` æ˜¯å¦æœ‰ç›¸é—œå¥—ä»¶ï¼Œè‹¥ç„¡å‰‡å»ºè­°åŠ å…¥æˆ–ç›´æ¥å®‰è£ã€‚
2.  **å»ºç«‹æª”æ¡ˆ**ï¼šè‡ªå‹•å»ºç«‹ `src/scraper.py` å’Œ `tests/test_scraper.py`ã€‚
3.  **æ’°å¯«ç¨‹å¼ç¢¼**ï¼š
    ```python
    # src/scraper.py
    import requests
    from bs4 import BeautifulSoup

    def get_page_title(url):
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            return soup.title.string.strip() if soup.title else None
        except Exception as e:
            print(f"Error fetching {url}: {e}")
            return None
    ```
4.  **é©—è­‰**ï¼šAgent ä¸»å‹•åŸ·è¡Œ `pytest`ã€‚
    - *å³ä¾¿å¤±æ•—*ï¼šå¦‚æœæ¸¬è©¦å¤±æ•—ï¼ŒAgent æœƒè®€å–éŒ¯èª¤è¨Šæ¯ï¼Œè‡ªå‹•ä¿®æ­£ç¨‹å¼ç¢¼ï¼Œç›´åˆ°æ¸¬è©¦é€šéã€‚

### 4. ä½ çš„å·¥ä½œï¼šå¯©é–± (Review)
ç•¶ä»»å‹™å®Œæˆå¾Œï¼ŒIDE æœƒé¡¯ç¤º **Diff View**ï¼ˆå·®ç•°æª¢è¦–æ¨¡å¼ï¼‰ã€‚
- **æª¢æŸ¥è®Šæ›´**ï¼šå·¦å´æ˜¯åŸæª”æ¡ˆï¼ˆè‹¥æœ‰ï¼‰ï¼Œå³å´æ˜¯æ–°å…§å®¹ã€‚
- **æ¥å—è®Šæ›´**ï¼šå¦‚æœæ»¿æ„ï¼Œé»æ“Š **ã€ŒAcceptã€** æˆ– **ã€ŒCommitã€** ä¿å­˜è®Šæ›´ã€‚

ğŸŸ¢ **å„ªé»**ï¼š
- **é›¶åˆ‡æ›**ï¼šä½ åœç•™åœ¨ IDE ä¸­ã€‚
- **è‡ªå‹•é–‰è¿´è·¯**ï¼šAgent è‡ªå·±å¯«ã€è‡ªå·±æ¸¬ã€è‡ªå·±ä¿®ã€‚
- **å°ˆæ³¨æ¶æ§‹**ï¼šä½ é—œæ³¨çš„æ˜¯ã€ŒåŠŸèƒ½ä»‹é¢ã€èˆ‡ã€ŒéŒ¯èª¤è™•ç†ç­–ç•¥ã€ï¼Œè€Œé `import` èªæ³•ç´°ç¯€ã€‚
